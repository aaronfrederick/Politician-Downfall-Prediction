{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_curve, confusion_matrix\n",
    "from sklearn import svm\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('data/X_train.pkl')\n",
    "y = pd.read_pickle('data/y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(0,axis=1)\n",
    "# X = X.drop(67,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22554,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  GridSearch Cross-Validation  ###\n",
    "###  Change scoring for different evaluations  ###\n",
    "\n",
    "# top_models = []\n",
    "# models1 = [LogisticRegression(class_weight='balanced'),\n",
    "#           svm.LinearSVC(class_weight='balanced'),\n",
    "#           svm.SVC(kernel = 'rbf', class_weight='balanced')]\n",
    "# grid = {'C':np.logspace(-3,2,10)}\n",
    "# for model in models1:\n",
    "#     print(model)\n",
    "#     gscv = RandomizedSearchCV(model,param_distributions=grid,n_jobs=-1,cv=4, scoring='precision')\n",
    "#     gscv.fit(X_train,y_train)\n",
    "#     print(gscv.best_estimator_)\n",
    "#     print(gscv.best_score_)\n",
    "#     top_models.append(gscv.best_estimator_)\n",
    "#     print()\n",
    "#     #print(gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  RandomSearchCV Round 3  ###\n",
    "###  Change scoring for different evaluations  ###\n",
    "\n",
    "# models3 =[DecisionTreeClassifier(class_weight='balanced'),\n",
    "#           RandomForestClassifier(class_weight='balanced'),\n",
    "#           GradientBoostingClassifier()]\n",
    "# grid = {}\n",
    "# for model in models3:\n",
    "#     print(model)\n",
    "#     gscv3 = RandomizedSearchCV(model,param_distributions=grid,n_iter=20,n_jobs=-1,cv=4,scoring='precision')\n",
    "#     gscv3.fit(X_train,y_train)\n",
    "#     print(gscv3.best_estimator_)\n",
    "#     print(gscv3.best_score_)\n",
    "#     top_models.append(gscv3.best_estimator_)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6716\n",
      "           1       0.13      0.16      0.14        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6767\n",
      "   macro avg       0.56      0.57      0.57      6767\n",
      "weighted avg       0.99      0.99      0.99      6767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  Top Predictor Optimized for Recall  ###\n",
    "###  Use for first-sign-of-danger  ###\n",
    "\n",
    "top_recall = svm.SVC(C=0.001, class_weight='balanced', kernel='rbf')\n",
    "top_recall.fit(X_train,y_train)\n",
    "print(classification_report(y_test,top_recall.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6716\n",
      "           1       0.22      0.25      0.24        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6767\n",
      "   macro avg       0.61      0.62      0.62      6767\n",
      "weighted avg       0.99      0.99      0.99      6767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  Top Predictor Optimized for F1  ###\n",
    "###  Use for Medium Alert Threshold  ###\n",
    "\n",
    "top_fone = svm.SVC(C=7.74, kernel='rbf',class_weight='balanced')\n",
    "top_fone.fit(X_train,y_train)\n",
    "print(classification_report(y_test,top_fone.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6716\n",
      "           1       0.50      0.04      0.07        51\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6767\n",
      "   macro avg       0.75      0.52      0.53      6767\n",
      "weighted avg       0.99      0.99      0.99      6767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  Top Predictor Optimized for Precision  ###\n",
    "###  Use for Red-Alert Choose-New-Candidate  ###\n",
    "\n",
    "top_precision = RandomForestClassifier(class_weight='balanced')\n",
    "top_precision.fit(X_train,y_train)\n",
    "print(classification_report(y_test,top_precision.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Models on Completely Unseen Data\n",
    "\n",
    "Here, the models will be tested on politicians they have not encountered before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout = pd.read_pickle('data/X_test.pkl')\n",
    "y_holdout = pd.read_pickle('data/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_holdout = X_holdout.drop([i for i in range(50,65,1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Balancing Columns from Training and Testing\n",
    "for col in X.columns:\n",
    "    if col not in X_holdout.columns:\n",
    "        X_holdout[col] = 0\n",
    "for col in X_holdout:\n",
    "    if col not in X.columns:\n",
    "        X_holdout = X_holdout.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_holdout = X_holdout.drop([0,67], axis=1)\n",
    "X_holdout = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Recall Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      9595\n",
      "           1       0.21      0.24      0.22        72\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      9667\n",
      "   macro avg       0.60      0.61      0.61      9667\n",
      "weighted avg       0.99      0.99      0.99      9667\n",
      "\n",
      "0.9875866349436226\n",
      "\n",
      "Top F1 Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      9595\n",
      "           1       0.31      0.38      0.34        72\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      9667\n",
      "   macro avg       0.65      0.68      0.67      9667\n",
      "weighted avg       0.99      0.99      0.99      9667\n",
      "\n",
      "0.9891383055756698\n",
      "\n",
      "Top Precision Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      9595\n",
      "           1       1.00      0.06      0.11        72\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      9667\n",
      "   macro avg       1.00      0.53      0.55      9667\n",
      "weighted avg       0.99      0.99      0.99      9667\n",
      "\n",
      "0.9929657598013861\n"
     ]
    }
   ],
   "source": [
    "print('Top Recall Model')\n",
    "print(classification_report(y_holdout,top_recall.predict(X_holdout)))\n",
    "print(top_recall.score(X_holdout, y_holdout))\n",
    "print()\n",
    "print('Top F1 Model')\n",
    "print(classification_report(y_holdout,top_fone.predict(X_holdout)))\n",
    "print(top_fone.score(X_holdout,y_holdout))\n",
    "print()\n",
    "print('Top Precision Model')\n",
    "print(classification_report(y_holdout,top_precision.predict(X_holdout)))\n",
    "print(top_precision.score(X_holdout,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_df = pd.read_pickle('ordered_df.pkl')\n",
    "ord_df = ord_df.reset_index()\n",
    "predictions = ord_df.iloc[-100:].drop('index',axis=1)\n",
    "X_predict = predictions.drop([0,1,67,'label','Week_Label'], axis=1)\n",
    "X_predict = X_predict.drop([i for i in range(50,65,1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 81)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fone.predict(X_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with only Document Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc = X\n",
    "for column in X.columns:\n",
    "    if type(column) == str:\n",
    "        X_doc = X_doc.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dummies = pd.get_dummies(X_doc[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc = pd.merge(X_doc,cluster_dummies,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(X_doc,y,test_size = 0.3, stratify=y)\n",
    "scaler2 = StandardScaler()\n",
    "X_train2 = scaler2.fit_transform(X_train2)\n",
    "X_test2 = scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.046415888336127795, class_weight='balanced',\n",
      "          dual=False, fit_intercept=True, intercept_scaling=1,\n",
      "          max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "          random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "          warm_start=False)\n",
      "0.01505556883188548\n",
      "\n",
      "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.5994842503189409, class_weight='balanced', dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "     tol=0.0001, verbose=0)\n",
      "0.031536588689770474\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "SVC(C=27.825594022071257, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "0.044197113505036086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  GridSearch Cross-Validation  ###\n",
    "###  Change scoring for different evaluations  ###\n",
    "\n",
    "top_models = []\n",
    "models1 = [LogisticRegression(class_weight='balanced'),\n",
    "          svm.LinearSVC(class_weight='balanced'),\n",
    "          svm.SVC(kernel = 'rbf', class_weight='balanced')]\n",
    "grid = {'C':np.logspace(-3,2,10)}\n",
    "for model in models1:\n",
    "    print(model)\n",
    "    gscv4 = RandomizedSearchCV(model,param_distributions=grid,n_jobs=-1,cv=4, scoring='precision')\n",
    "    gscv4.fit(X_train2,y_train2)\n",
    "    print(gscv4.best_estimator_)\n",
    "    print(gscv4.best_score_)\n",
    "    top_models.append(gscv4.best_estimator_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.014425677897751702\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators='warn', n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "0.0\n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "0.05968338725554741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  RandomSearchCV Round 3  ###\n",
    "###  Change scoring for different evaluations  ###\n",
    "\n",
    "models3 =[DecisionTreeClassifier(class_weight='balanced'),\n",
    "          RandomForestClassifier(class_weight='balanced'),\n",
    "          GradientBoostingClassifier()]\n",
    "grid = {}\n",
    "for model in models3:\n",
    "    print(model)\n",
    "    gscv5 = RandomizedSearchCV(model,param_distributions=grid,n_iter=20,n_jobs=-1,cv=4,scoring='precision')\n",
    "    gscv5.fit(X_train2,y_train2)\n",
    "    print(gscv5.best_estimator_)\n",
    "    print(gscv5.best_score_)\n",
    "    top_models.append(gscv5.best_estimator_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.23      9595\n",
      "           1       0.01      0.97      0.02        72\n",
      "\n",
      "   micro avg       0.14      0.14      0.14      9667\n",
      "   macro avg       0.50      0.55      0.12      9667\n",
      "weighted avg       0.99      0.14      0.23      9667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###  Top Predictor Optimized for Recall  ###\n",
    "###  Use for Low Alert Threshold  ###\n",
    "\n",
    "top_recall = svm.SVC(C=0.001, class_weight='balanced', kernel='rbf')\n",
    "top_recall.fit(X_train2,y_train2)\n",
    "print(classification_report(y_test2,top_recall.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Top Predictor Optimized for F1  ###\n",
    "###  Use for Medium Alert Threshold  ###\n",
    "\n",
    "#no good predictor, all f1s are very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Top Predictor Optimized for Precision  ###\n",
    "###  Use for Red-Alert Choose-New-Candidate  ###\n",
    "\n",
    "top_precision = RandomForestClassifier(class_weight='balanced')\n",
    "top_precision.fit(X_train,y_train)\n",
    "print(classification_report(y_test,top_precision.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9341, 81)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
